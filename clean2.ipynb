{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = 'data/'\n",
    "model_dir = 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prashant\\.conda\\envs\\bittergcn\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import scikitplot as skplt\n",
    "\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool, global_max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.utils import read_data, preprocess, train, test, run_kfold_test\n",
    "from source.models import BitterGCN_Baseline, BitterGCN_MixedPool, BitterGAT_Baseline, \\\n",
    "    BitterGAT_MixedPool, BitterGraphSAGE_Baseline, BitterGraphSAGE_MixedPool\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[2, 20], edge_index=[2, 2], y=0),\n",
       " Data(x=[8, 20], edge_index=[2, 14], y=1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k Fold\n",
    "nsplits = 10\n",
    "graph_data = preprocess(df)\n",
    "n=len(graph_data)\n",
    "graph_data[0], graph_data[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "KFOLD_RESULSTS = pd.DataFrame(index = list(range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitterGCN_Baseline(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels):\n",
    "        super(BitterGCN_Baseline, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = GCNConv(20, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv4 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv5 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, 2)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv5(x, edge_index)\n",
    "\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.3, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitterGCN_Baseline(\n",
      "  (conv1): GCNConv(20, 32)\n",
      "  (conv2): GCNConv(32, 32)\n",
      "  (conv3): GCNConv(32, 32)\n",
      "  (lin): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "Fold 1:\n",
      "Test Acc: 0.56 ROC: 0.41\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\SBI\\bitter peptides\\exp\\clean2.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBI/bitter%20peptides/exp/clean2.ipynb#ch0000008?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m BitterGCN_Baseline(hidden_channels\u001b[39m=\u001b[39mhidden_dim)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBI/bitter%20peptides/exp/clean2.ipynb#ch0000008?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SBI/bitter%20peptides/exp/clean2.ipynb#ch0000008?line=4'>5</a>\u001b[0m fold_test_acc, fold_test_roc \u001b[39m=\u001b[39m run_kfold_test(nsplits, graph_data, BitterGCN_Baseline, h\u001b[39m=\u001b[39;49mhidden_dim, lr \u001b[39m=\u001b[39;49m \u001b[39m0.05\u001b[39;49m, b\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBI/bitter%20peptides/exp/clean2.ipynb#ch0000008?line=6'>7</a>\u001b[0m KFOLD_RESULSTS\u001b[39m.\u001b[39mloc[:,\u001b[39m'\u001b[39m\u001b[39mACC_GCN_Baseline\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fold_test_acc\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBI/bitter%20peptides/exp/clean2.ipynb#ch0000008?line=7'>8</a>\u001b[0m KFOLD_RESULSTS\u001b[39m.\u001b[39mloc[:,\u001b[39m'\u001b[39m\u001b[39mROC_GCN_Baseline\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fold_test_roc\n",
      "File \u001b[1;32md:\\SBI\\bitter peptides\\exp\\source\\utils.py:122\u001b[0m, in \u001b[0;36mrun_kfold_test\u001b[1;34m(nsplits, graph_data, MODEL_INST, h, lr, b)\u001b[0m\n\u001b[0;32m    119\u001b[0m epochs_list \u001b[39m=\u001b[39m []\n\u001b[0;32m    121\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m30\u001b[39m):\n\u001b[1;32m--> 122\u001b[0m     train_acc, model \u001b[39m=\u001b[39m train(train_loader, model, optimizer, criterion)\n\u001b[0;32m    123\u001b[0m     test_acc, test_roc \u001b[39m=\u001b[39m test(test_loader, model)\n\u001b[0;32m    124\u001b[0m     epochs_list\u001b[39m.\u001b[39mappend(epoch)\n",
      "File \u001b[1;32md:\\SBI\\bitter peptides\\exp\\source\\utils.py:70\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, optimizer, criterion)\u001b[0m\n\u001b[0;32m     67\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m     69\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_loader:  \u001b[39m# Iterate in batches over the training dataset.\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m      out \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mx, data\u001b[39m.\u001b[39;49medge_index, data\u001b[39m.\u001b[39;49mbatch)  \u001b[39m# Perform a single forward pass.\u001b[39;00m\n\u001b[0;32m     71\u001b[0m      loss \u001b[39m=\u001b[39m criterion(out, data\u001b[39m.\u001b[39my)  \u001b[39m# Compute the loss.\u001b[39;00m\n\u001b[0;32m     72\u001b[0m      loss\u001b[39m.\u001b[39mbackward()  \u001b[39m# Derive gradients.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prashant\\.conda\\envs\\bittergcn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\SBI\\bitter peptides\\exp\\source\\models.py:22\u001b[0m, in \u001b[0;36mBitterGCN_Baseline.forward\u001b[1;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index, batch):\n\u001b[0;32m     21\u001b[0m     \u001b[39m# 1. Obtain node embeddings \u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     x1 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x, edge_index)\n\u001b[0;32m     23\u001b[0m     x1 \u001b[39m=\u001b[39m x1\u001b[39m.\u001b[39mrelu()\n\u001b[0;32m     24\u001b[0m     x2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x1, edge_index)\n",
      "File \u001b[1;32mc:\\Users\\prashant\\.conda\\envs\\bittergcn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\prashant\\.conda\\envs\\bittergcn\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:172\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    170\u001b[0m cache \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index\n\u001b[0;32m    171\u001b[0m \u001b[39mif\u001b[39;00m cache \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 172\u001b[0m     edge_index, edge_weight \u001b[39m=\u001b[39m gcn_norm(  \u001b[39m# yapf: disable\u001b[39;49;00m\n\u001b[0;32m    173\u001b[0m         edge_index, edge_weight, x\u001b[39m.\u001b[39;49msize(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim),\n\u001b[0;32m    174\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimproved, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_self_loops)\n\u001b[0;32m    175\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcached:\n\u001b[0;32m    176\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cached_edge_index \u001b[39m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[1;32mc:\\Users\\prashant\\.conda\\envs\\bittergcn\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:58\u001b[0m, in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, dtype)\u001b[0m\n\u001b[0;32m     54\u001b[0m     edge_weight \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mones((edge_index\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), ), dtype\u001b[39m=\u001b[39mdtype,\n\u001b[0;32m     55\u001b[0m                              device\u001b[39m=\u001b[39medge_index\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m     57\u001b[0m \u001b[39mif\u001b[39;00m add_self_loops:\n\u001b[1;32m---> 58\u001b[0m     edge_index, tmp_edge_weight \u001b[39m=\u001b[39m add_remaining_self_loops(\n\u001b[0;32m     59\u001b[0m         edge_index, edge_weight, fill_value, num_nodes)\n\u001b[0;32m     60\u001b[0m     \u001b[39massert\u001b[39;00m tmp_edge_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     61\u001b[0m     edge_weight \u001b[39m=\u001b[39m tmp_edge_weight\n",
      "File \u001b[1;32mc:\\Users\\prashant\\.conda\\envs\\bittergcn\\lib\\site-packages\\torch_geometric\\utils\\loop.py:198\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[39mr\u001b[39m\u001b[39m\"\"\"Adds remaining self-loop :math:`(i,i) \\in \\mathcal{E}` to every node\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39m:math:`i \\in \\mathcal{V}` in the graph given by :attr:`edge_index`.\u001b[39;00m\n\u001b[0;32m    176\u001b[0m \u001b[39mIn case the graph is weighted or has multi-dimensional edge features\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39m:rtype: (:class:`LongTensor`, :class:`Tensor`)\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    197\u001b[0m N \u001b[39m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[1;32m--> 198\u001b[0m mask \u001b[39m=\u001b[39m edge_index[\u001b[39m0\u001b[39;49m] \u001b[39m!=\u001b[39;49m edge_index[\u001b[39m1\u001b[39;49m]\n\u001b[0;32m    200\u001b[0m loop_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39marange(\u001b[39m0\u001b[39m, N, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong, device\u001b[39m=\u001b[39medge_index\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m    201\u001b[0m loop_index \u001b[39m=\u001b[39m loop_index\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m)\u001b[39m.\u001b[39mrepeat(\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_dim = 32\n",
    "model = BitterGCN_Baseline(hidden_channels=hidden_dim)\n",
    "print(model)\n",
    "\n",
    "fold_test_acc, fold_test_roc = run_kfold_test(nsplits, graph_data, BitterGCN_Baseline, h=hidden_dim, lr = 0.05, b=1)\n",
    "\n",
    "KFOLD_RESULSTS.loc[:,'ACC_GCN_Baseline'] = fold_test_acc\n",
    "KFOLD_RESULSTS.loc[:,'ROC_GCN_Baseline'] = fold_test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACC_GCN_Baseline    0.803\n",
       "ROC_GCN_Baseline    0.852\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KFOLD_RESULSTS.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitterGCN_Baseline(\n",
      "  (conv1): GCNConv(20, 32)\n",
      "  (conv2): GCNConv(32, 32)\n",
      "  (conv3): GCNConv(32, 32)\n",
      "  (lin): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "Fold 1:\n",
      "Test Acc: 0.86 ROC: 0.86\n",
      "Fold 2:\n",
      "Test Acc: 0.92 ROC: 0.95\n",
      "Fold 3:\n",
      "Test Acc: 0.81 ROC: 0.9\n",
      "Fold 4:\n",
      "Test Acc: 0.81 ROC: 0.88\n",
      "Fold 5:\n",
      "Test Acc: 0.81 ROC: 0.88\n",
      "Fold 6:\n",
      "Test Acc: 0.91 ROC: 0.92\n",
      "Fold 7:\n",
      "Test Acc: 0.81 ROC: 0.88\n",
      "Fold 8:\n",
      "Test Acc: 0.8 ROC: 0.86\n",
      "Fold 9:\n",
      "Test Acc: 0.77 ROC: 0.85\n",
      "Fold 10:\n",
      "Test Acc: 0.72 ROC: 0.76\n"
     ]
    }
   ],
   "source": [
    "hidden_dim = 32\n",
    "model = BitterGCN_Baseline(hidden_channels=hidden_dim)\n",
    "print(model)\n",
    "\n",
    "fold_test_acc, fold_test_roc = run_kfold_test(nsplits, graph_data, BitterGCN_Baseline, h=hidden_dim)\n",
    "\n",
    "KFOLD_RESULSTS.loc[:,'ACC_GCN_Baseline'] = fold_test_acc\n",
    "KFOLD_RESULSTS.loc[:,'ROC_GCN_Baseline'] = fold_test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACC_GCN_Baseline    0.822\n",
       "ROC_GCN_Baseline    0.874\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KFOLD_RESULSTS.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitterGCN_MixedPool(\n",
      "  (conv1): GCNConv(20, 32)\n",
      "  (conv2): GCNConv(32, 32)\n",
      "  (conv3): GCNConv(32, 32)\n",
      "  (lin): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "Fold 1:\n",
      "Test Acc: 0.86 ROC: 0.86\n",
      "Fold 2:\n",
      "Test Acc: 0.95 ROC: 0.98\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\SBI\\bitter peptides\\exp\\clean2.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBI/bitter%20peptides/exp/clean2.ipynb#ch0000009?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m BitterGCN_MixedPool(hidden_channels\u001b[39m=\u001b[39m\u001b[39m32\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBI/bitter%20peptides/exp/clean2.ipynb#ch0000009?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(model)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/SBI/bitter%20peptides/exp/clean2.ipynb#ch0000009?line=3'>4</a>\u001b[0m fold_test_acc, fold_test_roc \u001b[39m=\u001b[39m run_kfold_test(nsplits, graph_data, BitterGCN_MixedPool)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBI/bitter%20peptides/exp/clean2.ipynb#ch0000009?line=5'>6</a>\u001b[0m KFOLD_RESULSTS\u001b[39m.\u001b[39mloc[:,\u001b[39m'\u001b[39m\u001b[39mACC_GCN_MixedPool\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fold_test_acc\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/SBI/bitter%20peptides/exp/clean2.ipynb#ch0000009?line=6'>7</a>\u001b[0m KFOLD_RESULSTS\u001b[39m.\u001b[39mloc[:,\u001b[39m'\u001b[39m\u001b[39mROC_GCN_MixedPool\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fold_test_roc\n",
      "File \u001b[1;32md:\\SBI\\bitter peptides\\exp\\source\\utils.py:122\u001b[0m, in \u001b[0;36mrun_kfold_test\u001b[1;34m(nsplits, graph_data, MODEL_INST, h, lr)\u001b[0m\n\u001b[0;32m    119\u001b[0m epochs_list \u001b[39m=\u001b[39m []\n\u001b[0;32m    121\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m30\u001b[39m):\n\u001b[1;32m--> 122\u001b[0m     train_acc, model \u001b[39m=\u001b[39m train(train_loader, model, optimizer, criterion)\n\u001b[0;32m    123\u001b[0m     test_acc, test_roc \u001b[39m=\u001b[39m test(test_loader, model)\n\u001b[0;32m    124\u001b[0m     epochs_list\u001b[39m.\u001b[39mappend(epoch)\n",
      "File \u001b[1;32md:\\SBI\\bitter peptides\\exp\\source\\utils.py:80\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader, model, optimizer, criterion)\u001b[0m\n\u001b[0;32m     78\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     79\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m train_loader:  \u001b[39m# Iterate in batches over the training/test dataset.\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m     out \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mx, data\u001b[39m.\u001b[39;49medge_index, data\u001b[39m.\u001b[39;49mbatch)  \n\u001b[0;32m     81\u001b[0m     pred \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39margmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# Use the class with highest probability.\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     correct \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mint\u001b[39m((pred \u001b[39m==\u001b[39m data\u001b[39m.\u001b[39my)\u001b[39m.\u001b[39msum())  \u001b[39m# Check against ground-truth labels.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prashant\\.conda\\envs\\bittergcn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\SBI\\bitter peptides\\exp\\source\\models.py:53\u001b[0m, in \u001b[0;36mBitterGCN_MixedPool.forward\u001b[1;34m(self, x, edge_index, batch)\u001b[0m\n\u001b[0;32m     51\u001b[0m x2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x1, edge_index)\n\u001b[0;32m     52\u001b[0m x2 \u001b[39m=\u001b[39m x2\u001b[39m.\u001b[39mrelu()\n\u001b[1;32m---> 53\u001b[0m x3 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv3(x2, edge_index)\n\u001b[0;32m     55\u001b[0m \u001b[39m# 2. Readout layer [batch_size, hidden_channels]\u001b[39;00m\n\u001b[0;32m     56\u001b[0m x \u001b[39m=\u001b[39m global_max_pool(x3, batch) \u001b[39m+\u001b[39m \\\n\u001b[0;32m     57\u001b[0m     global_add_pool(x3, batch) \u001b[39m+\u001b[39m \\\n\u001b[0;32m     58\u001b[0m     global_mean_pool(x3, batch)\u001b[39m# [batch_size, hidden_channels]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\prashant\\.conda\\envs\\bittergcn\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\prashant\\.conda\\envs\\bittergcn\\lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:194\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    191\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin(x)\n\u001b[0;32m    193\u001b[0m \u001b[39m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, edge_weight\u001b[39m=\u001b[39;49medge_weight,\n\u001b[0;32m    195\u001b[0m                      size\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    197\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    198\u001b[0m     out \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias\n",
      "File \u001b[1;32mc:\\Users\\prashant\\.conda\\envs\\bittergcn\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:309\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[1;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m decomp_args:\n\u001b[0;32m    307\u001b[0m         kwargs[arg] \u001b[39m=\u001b[39m decomp_kwargs[arg][i]\n\u001b[1;32m--> 309\u001b[0m coll_dict \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__collect__(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__user_args__, edge_index,\n\u001b[0;32m    310\u001b[0m                              size, kwargs)\n\u001b[0;32m    312\u001b[0m msg_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minspector\u001b[39m.\u001b[39mdistribute(\u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m, coll_dict)\n\u001b[0;32m    313\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_pre_hooks\u001b[39m.\u001b[39mvalues():\n",
      "File \u001b[1;32mc:\\Users\\prashant\\.conda\\envs\\bittergcn\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:202\u001b[0m, in \u001b[0;36mMessagePassing.__collect__\u001b[1;34m(self, args, edge_index, size, kwargs)\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Tensor):\n\u001b[0;32m    201\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__set_size__(size, dim, data)\n\u001b[1;32m--> 202\u001b[0m             data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__lift__(data, edge_index, dim)\n\u001b[0;32m    204\u001b[0m         out[arg] \u001b[39m=\u001b[39m data\n\u001b[0;32m    206\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_index, Tensor):\n",
      "File \u001b[1;32mc:\\Users\\prashant\\.conda\\envs\\bittergcn\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:172\u001b[0m, in \u001b[0;36mMessagePassing.__lift__\u001b[1;34m(self, src, edge_index, dim)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_index, Tensor):\n\u001b[0;32m    171\u001b[0m     index \u001b[39m=\u001b[39m edge_index[dim]\n\u001b[1;32m--> 172\u001b[0m     \u001b[39mreturn\u001b[39;00m src\u001b[39m.\u001b[39;49mindex_select(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim, index)\n\u001b[0;32m    173\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_index, SparseTensor):\n\u001b[0;32m    174\u001b[0m     \u001b[39mif\u001b[39;00m dim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BitterGCN_MixedPool(hidden_channels=32)\n",
    "print(model)\n",
    "\n",
    "fold_test_acc, fold_test_roc = run_kfold_test(nsplits, graph_data, BitterGCN_MixedPool)\n",
    "\n",
    "KFOLD_RESULSTS.loc[:,'ACC_GCN_MixedPool'] = fold_test_acc\n",
    "KFOLD_RESULSTS.loc[:,'ROC_GCN_MixedPool'] = fold_test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitterGAT_Baseline(\n",
      "  (conv1): GATConv(20, 32, heads=1)\n",
      "  (conv2): GATConv(32, 32, heads=1)\n",
      "  (conv3): GATConv(32, 32, heads=1)\n",
      "  (lin): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "Fold 1:\n",
      "Test Acc: 0.78 ROC: 0.81\n",
      "Fold 2:\n",
      "Test Acc: 0.81 ROC: 0.91\n",
      "Fold 3:\n",
      "Test Acc: 0.83 ROC: 0.85\n",
      "Fold 4:\n",
      "Test Acc: 0.88 ROC: 0.9\n",
      "Fold 5:\n",
      "Test Acc: 0.81 ROC: 0.85\n",
      "Fold 6:\n",
      "Test Acc: 0.84 ROC: 0.92\n",
      "Fold 7:\n",
      "Test Acc: 0.78 ROC: 0.93\n",
      "Fold 8:\n",
      "Test Acc: 0.88 ROC: 0.91\n",
      "Fold 9:\n",
      "Test Acc: 0.81 ROC: 0.87\n",
      "Fold 10:\n",
      "Test Acc: 0.7 ROC: 0.83\n"
     ]
    }
   ],
   "source": [
    "model = BitterGAT_Baseline(hidden_channels=32)\n",
    "print(model)\n",
    "\n",
    "fold_test_acc, fold_test_roc = run_kfold_test(nsplits, graph_data, BitterGAT_Baseline)\n",
    "\n",
    "KFOLD_RESULSTS.loc[:,'ACC_GAT_Baseline'] = fold_test_acc\n",
    "KFOLD_RESULSTS.loc[:,'ROC_GAT_Baseline'] = fold_test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitterGAT_MixedPool(\n",
      "  (conv1): GATConv(20, 32, heads=1)\n",
      "  (conv2): GATConv(32, 32, heads=1)\n",
      "  (conv3): GATConv(32, 32, heads=1)\n",
      "  (lin): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "Fold 1:\n",
      "Test Acc: 0.8 ROC: 0.85\n",
      "Fold 2:\n",
      "Test Acc: 0.83 ROC: 0.97\n",
      "Fold 3:\n",
      "Test Acc: 0.84 ROC: 0.9\n",
      "Fold 4:\n",
      "Test Acc: 0.89 ROC: 0.89\n",
      "Fold 5:\n",
      "Test Acc: 0.78 ROC: 0.84\n",
      "Fold 6:\n",
      "Test Acc: 0.88 ROC: 0.93\n",
      "Fold 7:\n",
      "Test Acc: 0.86 ROC: 0.93\n",
      "Fold 8:\n",
      "Test Acc: 0.8 ROC: 0.91\n",
      "Fold 9:\n",
      "Test Acc: 0.8 ROC: 0.89\n",
      "Fold 10:\n",
      "Test Acc: 0.78 ROC: 0.85\n"
     ]
    }
   ],
   "source": [
    "model = BitterGAT_MixedPool(hidden_channels=32)\n",
    "print(model)\n",
    "\n",
    "fold_test_acc, fold_test_roc = run_kfold_test(nsplits, graph_data, BitterGAT_MixedPool)\n",
    "\n",
    "KFOLD_RESULSTS.loc[:,'ACC_GAT_MixedPool'] = fold_test_acc\n",
    "KFOLD_RESULSTS.loc[:,'ROC_GAT_MixedPool'] = fold_test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitterGraphSAGE_Baseline(\n",
      "  (conv1): SAGEConv(20, 32)\n",
      "  (conv2): SAGEConv(32, 32)\n",
      "  (conv3): SAGEConv(32, 32)\n",
      "  (lin): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "Fold 1:\n",
      "Test Acc: 0.77 ROC: 0.86\n",
      "Fold 2:\n",
      "Test Acc: 0.89 ROC: 0.91\n",
      "Fold 3:\n",
      "Test Acc: 0.81 ROC: 0.92\n",
      "Fold 4:\n",
      "Test Acc: 0.77 ROC: 0.88\n",
      "Fold 5:\n",
      "Test Acc: 0.84 ROC: 0.88\n",
      "Fold 6:\n",
      "Test Acc: 0.84 ROC: 0.91\n",
      "Fold 7:\n",
      "Test Acc: 0.84 ROC: 0.93\n",
      "Fold 8:\n",
      "Test Acc: 0.84 ROC: 0.9\n",
      "Fold 9:\n",
      "Test Acc: 0.8 ROC: 0.82\n",
      "Fold 10:\n",
      "Test Acc: 0.72 ROC: 0.82\n"
     ]
    }
   ],
   "source": [
    "model = BitterGraphSAGE_Baseline(hidden_channels=32)\n",
    "print(model)\n",
    "\n",
    "fold_test_acc, fold_test_roc = run_kfold_test(nsplits, graph_data, BitterGraphSAGE_Baseline)\n",
    "\n",
    "KFOLD_RESULSTS.loc[:,'ACC_GraphSAGE_Baseline'] = fold_test_acc\n",
    "KFOLD_RESULSTS.loc[:,'ROC_GraphSAGE_Baseline'] = fold_test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BitterGraphSAGE_MixedPool(\n",
      "  (conv1): SAGEConv(20, 32)\n",
      "  (conv2): SAGEConv(32, 32)\n",
      "  (conv3): SAGEConv(32, 32)\n",
      "  (lin): Linear(in_features=32, out_features=2, bias=True)\n",
      ")\n",
      "Fold 1:\n",
      "Test Acc: 0.75 ROC: 0.86\n",
      "Fold 2:\n",
      "Test Acc: 0.89 ROC: 0.94\n",
      "Fold 3:\n",
      "Test Acc: 0.86 ROC: 0.9\n",
      "Fold 4:\n",
      "Test Acc: 0.83 ROC: 0.91\n",
      "Fold 5:\n",
      "Test Acc: 0.83 ROC: 0.85\n",
      "Fold 6:\n",
      "Test Acc: 0.84 ROC: 0.89\n",
      "Fold 7:\n",
      "Test Acc: 0.81 ROC: 0.93\n",
      "Fold 8:\n",
      "Test Acc: 0.8 ROC: 0.91\n",
      "Fold 9:\n",
      "Test Acc: 0.83 ROC: 0.87\n",
      "Fold 10:\n",
      "Test Acc: 0.81 ROC: 0.83\n"
     ]
    }
   ],
   "source": [
    "model = BitterGraphSAGE_MixedPool(hidden_channels=32)\n",
    "print(model)\n",
    "\n",
    "fold_test_acc, fold_test_roc = run_kfold_test(nsplits, graph_data, BitterGraphSAGE_MixedPool)\n",
    "\n",
    "KFOLD_RESULSTS.loc[:,'ACC_GraphSAGE_MixedPool'] = fold_test_acc\n",
    "KFOLD_RESULSTS.loc[:,'ROC_GraphSAGE_MixedPool'] = fold_test_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACC_GCN_Baseline</th>\n",
       "      <th>ROC_GCN_Baseline</th>\n",
       "      <th>ACC_GCN_MixedPool</th>\n",
       "      <th>ROC_GCN_MixedPool</th>\n",
       "      <th>ACC_GAT_Baseline</th>\n",
       "      <th>ROC_GAT_Baseline</th>\n",
       "      <th>ACC_GAT_MixedPool</th>\n",
       "      <th>ROC_GAT_MixedPool</th>\n",
       "      <th>ACC_GraphSAGE_Baseline</th>\n",
       "      <th>ROC_GraphSAGE_Baseline</th>\n",
       "      <th>ACC_GraphSAGE_MixedPool</th>\n",
       "      <th>ROC_GraphSAGE_MixedPool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.84</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.78</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ACC_GCN_Baseline  ROC_GCN_Baseline  ACC_GCN_MixedPool  ROC_GCN_MixedPool  \\\n",
       "0              0.81              0.81               0.86               0.86   \n",
       "1              0.91              0.97               0.95               0.98   \n",
       "2              0.84              0.89               0.91               0.91   \n",
       "3              0.84              0.91               0.89               0.91   \n",
       "4              0.80              0.83               0.77               0.85   \n",
       "5              0.84              0.92               0.86               0.90   \n",
       "6              0.81              0.92               0.88               0.92   \n",
       "7              0.89              0.90               0.81               0.87   \n",
       "8              0.80              0.86               0.88               0.89   \n",
       "9              0.78              0.77               0.77               0.80   \n",
       "\n",
       "   ACC_GAT_Baseline  ROC_GAT_Baseline  ACC_GAT_MixedPool  ROC_GAT_MixedPool  \\\n",
       "0              0.78              0.81               0.80               0.85   \n",
       "1              0.81              0.91               0.83               0.97   \n",
       "2              0.83              0.85               0.84               0.90   \n",
       "3              0.88              0.90               0.89               0.89   \n",
       "4              0.81              0.85               0.78               0.84   \n",
       "5              0.84              0.92               0.88               0.93   \n",
       "6              0.78              0.93               0.86               0.93   \n",
       "7              0.88              0.91               0.80               0.91   \n",
       "8              0.81              0.87               0.80               0.89   \n",
       "9              0.70              0.83               0.78               0.85   \n",
       "\n",
       "   ACC_GraphSAGE_Baseline  ROC_GraphSAGE_Baseline  ACC_GraphSAGE_MixedPool  \\\n",
       "0                    0.77                    0.86                     0.75   \n",
       "1                    0.89                    0.91                     0.89   \n",
       "2                    0.81                    0.92                     0.86   \n",
       "3                    0.77                    0.88                     0.83   \n",
       "4                    0.84                    0.88                     0.83   \n",
       "5                    0.84                    0.91                     0.84   \n",
       "6                    0.84                    0.93                     0.81   \n",
       "7                    0.84                    0.90                     0.80   \n",
       "8                    0.80                    0.82                     0.83   \n",
       "9                    0.72                    0.82                     0.81   \n",
       "\n",
       "   ROC_GraphSAGE_MixedPool  \n",
       "0                     0.86  \n",
       "1                     0.94  \n",
       "2                     0.90  \n",
       "3                     0.91  \n",
       "4                     0.85  \n",
       "5                     0.89  \n",
       "6                     0.93  \n",
       "7                     0.91  \n",
       "8                     0.87  \n",
       "9                     0.83  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KFOLD_RESULSTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ACC_GCN_Baseline           0.832\n",
       "ROC_GCN_Baseline           0.878\n",
       "ACC_GCN_MixedPool          0.858\n",
       "ROC_GCN_MixedPool          0.889\n",
       "ACC_GAT_Baseline           0.812\n",
       "ROC_GAT_Baseline           0.878\n",
       "ACC_GAT_MixedPool          0.826\n",
       "ROC_GAT_MixedPool          0.896\n",
       "ACC_GraphSAGE_Baseline     0.812\n",
       "ROC_GraphSAGE_Baseline     0.883\n",
       "ACC_GraphSAGE_MixedPool    0.825\n",
       "ROC_GraphSAGE_MixedPool    0.889\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KFOLD_RESULSTS.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('bittergcn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "70d680ff6d465e39e32d4aba16f881a1997a3179fab20e951184281a6d1cc528"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
