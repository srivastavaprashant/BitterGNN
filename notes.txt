eBitterGCN: expnainable Bitter peptide classification with Graph Convolutional Networks
The motivation is to predict the bitter taste of the peptides from their descriptor sequences while explaining the importance of descriptors of the peptides. The BT640 dataset has 320 bitter and 320 non-bitter peptide descriptor sequences with labels 0/1. I created three notebooks for three different train-test data splits. There are two steps in each notebook: GCN classification model training & validation and explanation of individual descriptor in all peptides
Introdcution:

- Background
    -Importance of bitter peptides
    -AI for decision making in the field
        - Bitter taste receptor modelling  
        - Classification of bitter peptides 

- Data for bitter peptides
    - Quantifying bitterness
        - Binary classification
        - Bitterness: Q-value?

    - Data Types:
        - SMILES 2D structures
        - 3D molecular structures 
        - Aminoacid descriptor sequences

    - Available datasets
        - BitterDB: Regression
        - BT640: Classification 

- Previous work and SOTA

    - BitterPredict (2017): 
        - Classification for BitterDB, 
        - Used molecular descriptors (ADME/TOX from QikProp + additional),
        - AdaBoost, 
        - PCA embedding,
        - Feature Importance
    
    - BitterX (2015):
        - Classification using bitterant-TAS2R interactions,
        - SVM,
        - Used molecular descriptors (Checker and ChemAtom Standardizer),
        - Online Tool

    - eBitter (2018):
        - Classification for BitterDB,
        - Fingeprint,
        - KNN, SVM, RF, GBM, and DNN,
        - Feature Importance
        - Local Tool

    - BERT4Bitter (2021)
        - Descriptor based Classification
        - Pretrained network
    
    - iBitterSCM (2021)
        - Rule based classification
        - 


    - RNN, LSTM
    - attention 
            - BERT4Bitter  
                - pretrained
    
    - GNN (touch up briefly enough to justify Research gaps)
        - GNN embedding for Smell molecules
        - * GNN for peptide sequences

Methods

- Research Gap
    - Explainability of descriptors in peptide sequences
    - Peptide feature agnostic data to high dimensional graph embedding 
    - Graph neural networks not used before
    - Faster training than BERT

- Details of models used in the paper
    - GNN (elaborate including advantages over previous model and models used in the paper for experimenation)
        - GCN
        - GAT
        - graphSAGE

- Experiments:

- data (source, history, data points, preprocessing, summary stats - dist of length and destriptor population spread with bitter marker)

- Experimental protocol 
                        - shuffle, 10-fold CV, parameters, performance measures, 
                        - learned embedding extraction from trained model, 
                        - unsupervised models to visualize embedding, 
                        - post-processing to achieve descriptor level explainability

Results:
- Classification performances
- Unupervised analysis of learned graph embedding
- Explainability analysis results

Discussion:
- Justification that the research gaps were addressed
- Explainability at a data-scientific level
- Explainability from a food-science perspective (Antonella)

Conclusions